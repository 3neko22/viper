codex:
    model: quantized
    codellama_tokenizer_name: 'codellama/CodeLlama-7b-hf'
    prompt: ./prompts/benchmarks/refcoco.prompt
load_models:
    codex: False
    codellama: False
    quantized: True

# BEGIRATU PARAMETROEN ESPEZIFIKAZIOAK -> (Temperature, batch_size, ...)
